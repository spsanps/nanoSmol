# Session Handoff — 2026-02-21 (Updated)

## What's Running RIGHT NOW

**Full benchmark suite** running on A100 80GB:
```
Script: /workspace/run_benchmarks_fast.py (bf16, all 3 modes)
Log: /workspace/benchmark_run_fast.log
Benchmarks: Val10K (1000) → MVBench (3800) → Video-MME (2700) → POPE (9000)
```

**Image benchmark download** (POPE + ScienceQA) in progress.

Check status: `grep -E "\[MVBench\]\|\[Video-MME\]\|SUMMARY" /workspace/benchmark_run_fast.log | tail -10`

Results will be saved to: `/workspace/benchmark_results.json`

---

## Completed This Session

### 1. DPO Training (Stage 3) — FINISHED
- Resumed from step 1500, completed all 2593 steps
- Final: dpo_loss=0.629, reward_accuracy ~70%
- Checkpoint: `/workspace/checkpoints/final/stage3/best.pt` (step 2000)
- Checkpoint: `/workspace/checkpoints/final/stage3/step_0002593.pt` (latest/final)

### 2. HuggingFace Upload — DONE
- URL: https://huggingface.co/sanps/fVLM-135M
- Contents: model.safetensors (708MB), config.json, README, training configs, model code
- HF user: `sanps`

### 3. Inference Testing — DONE
- Tested all 3 modes (coarse_only, coarse_fine, autoregressive) on 10 val samples
- **Key finding:** Coarse-only hallucinates generic text. Fine and autoregressive produce grounded, accurate descriptions.
- Scripts: `/workspace/test_inference.py`, `/workspace/compare_captions.py`, `/workspace/compare_3mode.py`

### 4. Benchmarks — IN PROGRESS
Script: `/workspace/run_benchmarks.py`
Method: Log-likelihood MCQ scoring (compute loss per option, pick lowest)

**Completed results so far:**

| Benchmark | Coarse-Only | Coarse→Fine | Autoregressive |
|-----------|-------------|-------------|----------------|
| Val 10K (loss↓) | 1.882 | 1.534 | 1.532 |
| MVBench (acc↑) | 27.2% | 28.1% | 27.9% |
| Video-MME (acc↑) | ~25.5% | ~28.9% | ~29.5% |

Video-MME numbers are partial (550/2700), will finalize in benchmark_results.json.

**Baseline comparison (published SmolVLM2 numbers):**

| Model | Params | MVBench | Video-MME |
|-------|--------|---------|-----------|
| SmolVLM2-256M-Video | 256M | 32.7% | 33.7% |
| SmolVLM2-2.2B | 2.2B | 46.3% | 52.1% |
| Random (4-choice) | — | 25.0% | 25.0% |
| **fVLM-135M (ours)** | **157M** | **27.2-28.1%** | **~29.5%** |

### 5. TRAINING_PLAN.md — UPDATED
- All decision changes documented with rationale
- YAML config changes documented line-by-line
- Committed and pushed: `065783c`

---

## All 3 Training Stages Summary

| Stage | Steps | Samples | Duration | Metric | Checkpoint |
|-------|-------|---------|----------|--------|------------|
| Stage 1 (visual alignment) | 31,250 | 1M | 4.5h | val_loss=1.236 | `/workspace/checkpoints/final/stage1/` |
| Stage 2 (vision-language SFT) | 31,250 | 1M | 7.6h | train_loss=0.040 | `/workspace/checkpoints/final/stage2/` |
| Stage 3 (DPO) | 2,593 | 83K | 0.5h | dpo_loss=0.629 | `/workspace/checkpoints/final/stage3/` |

---

## Key File Locations

### Checkpoints
- Stage 1 best: `/workspace/checkpoints/final/stage1/best.pt` → step 7000
- Stage 2 best: `/workspace/checkpoints/final/stage2/best.pt` → step 27000
- Stage 3 best: `/workspace/checkpoints/final/stage3/best.pt` → step 2000
- Stage 3 final: `/workspace/checkpoints/final/stage3/step_0002593.pt`

### Training logs
- `/workspace/final_training_logs/chain.log` — stage orchestration log
- `/workspace/final_training_logs/stage1.log`
- `/workspace/final_training_logs/stage2.log`
- `/workspace/final_training_logs/stage3.log`

### Configs (modified, uncommitted)
- `release/configs/final/stage1_135M.yaml`
- `release/configs/final/stage2_135M.yaml`
- `release/configs/final/stage3_135M.yaml`

### Code (modified, uncommitted — +812 lines)
- `release/train.py` — DPO training loop, reference model, DPO loss
- `release/model/foveated_vlm.py` — `forward_dpo()` method
- `release/data/collate.py` — `collate_dpo()`
- `release/data/webdataset_loader.py` — `create_dpo_webdataset()`
- `release/scripts/precompute.py` — RLAIF-V shard generation

### Benchmark/eval scripts (not in repo)
- `/workspace/run_benchmarks.py` — full MCQ benchmark eval
- `/workspace/test_inference.py` — quick inference test
- `/workspace/compare_captions.py` — GT vs generated comparison
- `/workspace/compare_3mode.py` — 3-mode side-by-side
- `/workspace/upload_to_hf.py` — HuggingFace upload

### Models
- LLM: `/workspace/models/SmolLM2-135M-Instruct`
- DINO: `/workspace/models/dinov2-small`

### Data
- Val: `/workspace/data/eval/val_10k/*.tar` (10K samples)
- MVBench: `/workspace/data/eval/benchmarks/mvbench_shards/mvbench_*.tar` (3800 samples)
- Video-MME: `/workspace/data/eval/benchmarks/video_mme_shards/video_mme_*.tar` (2700 samples)
- MLVU: annotation only (`/workspace/data/eval/benchmarks/mlvu/mlvu/test-00000-of-00001.parquet`), NO video files
- RLAIF-V: `/workspace/data/rlaif_v/*.tar`

### Wandb
- Project: `foveated-vlm-final`
- User: `sanjayanps`
- Creds: `/workspace/.netrc`

### HuggingFace
- Repo: `sanps/fVLM-135M`
- Auth: logged in via `huggingface_hub` (token cached)

---

## Git Status

Branch: `main`
Last commit: `065783c` — docs: update TRAINING_PLAN with final status + change decisions
Remote: https://github.com/spsanps/nanoSmol.git

**Uncommitted changes (9 files, +812 lines):**
```
M release/configs/final/stage1_135M.yaml
M release/configs/final/stage2_135M.yaml
M release/configs/final/stage3_135M.yaml
M release/data/collate.py
M release/data/webdataset_loader.py
M release/model/foveated_vlm.py
M release/scripts/precompute.py
M release/train.py
```

These are the DPO implementation + config changes from the previous session. Should be committed.

---

## Dependencies Installed This Session

```bash
pip install --break-system-packages transformers accelerate wandb webdataset timm safetensors huggingface_hub pandas pyarrow
```

These are NOT in a requirements.txt — if the pod resets, reinstall.

---

## What's Next

1. **Wait for Video-MME to finish** → check `/workspace/benchmark_results.json`
2. **MLVU** — needs video download (1122 videos, avg 11 min each). Gated access at https://huggingface.co/datasets/MLVU/MVLU. Our 64-frame/64s cap makes this less ideal.
3. **Commit DPO code changes** — the +812 lines are still uncommitted
4. **Scale to 360M** — LR=7e-4 confirmed from sweep. Needs same 3-stage pipeline.
5. **Scale to 1.7B** — needs A100 80GB (OOM on RTX 5090 32GB even at bs=1)
6. **Update HF model card** with benchmark scores once finalized
