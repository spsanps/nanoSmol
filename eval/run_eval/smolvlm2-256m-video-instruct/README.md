# SmolVLM2-256M-Video-Instruct LightEval runner

```bash
python eval/run_eval/smolvlm2-256m-video-instruct/run.py
```

Identical ergonomics to the V1 helper: deterministic generation, chat templating, VLM backend and
bfloat16 weights.  Use the optional flags (`--max-samples`, `--dry-run`, `--extra-model-args`, â€¦) to
adapt the baseline command for bespoke experiments.
