# HellaSwag evaluation with SmolLM2-1.7B-Instruct
# Testing with length-normalized scoring
task: hellaswag
model:
  model_id: HuggingFaceTB/SmolLM2-1.7B-Instruct
  is_vlm: false
  dtype: bfloat16
  device: cuda
  trust_remote_code: true
  attn_impl: flash_attention_2
scoring:
  seed: 123
  # TODO: Add normalize_by_length parameter
report:
  output_dir: artifacts/nanoeval/hellaswag/smollm2-1.7b-normalized
  summary_filename: summary.json
  predictions_filename: predictions.jsonl
  table_filename: metrics.csv
  plot_filename: accuracy.png
  save_predictions: true
  save_table: true
  save_plot: true
dataset:
  split: validation
  subset_size: 100
